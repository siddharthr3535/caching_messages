Message Cache System

Overview
This program implements a message storage system with configurable caching and page replacement algorithms. Messages are stored on disk, and a subset is kept in memory (cache) for faster access.

Classes

Message
Contains: ID, Content, Sender, Receiver, Timestamp, Delivered flag
Enforces fixed message size limits (configurable via properties file)
Content, sender, and receiver fields are truncated if they exceed configured limits

CacheStorage
Represents a single node in the cache's doublylinked list
Contains: Message instance, previous pointer, next pointer
Used to maintain cache ordering for replacement algorithms

Cache
Implements caching with configurable replacement strategies (LRU, LIFO, Random)
Uses HashMap for O(1) message lookup by ID
Uses doublylinked list with dummy head/tail nodes for efficient insertion/deletion
Tracks cache hits and misses for performance evaluation
Supports three replacement strategies: LRU, LIFO, Random

MessageStorage
Handles disk I/O operations (storing and retrieving messages from files)
Creates binary files in 'messages/' directory (one file per message: 'msg\_<id>.bin')
Uses Java serialization for message persistence

MessageManager
Integrates cache and disk storage for transparent message access
Automatically handles cache misses by loading from disk
Provides unified interface for storing and retrieving messages
Demonstrates proper page loading from disk on cache miss

Config
Loads configuration from 'config.properties' file at runtime
Configurable parameters:
'message.size': Total size of each message (default: 512 bytes)
'cache.capacity': Maximum number of messages in cache (default: 16)
'max.content.length': Maximum content length (default: 384 chars)
'max.sender.length': Maximum sender name length (default: 50 chars)
'max.receiver.length': Maximum receiver name length (default: 50 chars)

Cache Implementation

Architecture
HashMap: Stores <MessageID, CacheStorage> pairs for O(1) lookup
DoublyLinked List: Maintains message order for replacement algorithms
Dummy head and tail nodes simplify insertion/deletion operations
No null pointer checks needed

Cache Operations

put

1. If message already exists in cache:
   Update the message content
   For LRU: move to front (most recently used position)
   For LIFO/Random: keep in current position
2. If message is new:
   Check if cache is full
   If full: evict message based on replacement strategy
   Add new message to front of list
   Add to HashMap

get

1. Check HashMap for message ID
2. If found (cache hit):
   For LRU: move to front (mark as recently used)
   For LIFO/Random: no reordering
   Return message
3. If not found (cache miss):
   Return null
   MessageManager loads from disk and adds to cache

Replacement Strategies

LRU
When cache is full: evicts the least recently accessed message
On access : moves message to front of list
Front (tail.prev) = most recently used, Back (head.next) = least recently used
Eviction: removes message at 'head.next'

LIFO
When cache is full: evicts the most recently added message
On access: does NOT reorder messages
Eviction: removes message at 'tail.prev' (most recently added)

Random
When cache is full: evicts a random message
On access: does not reorder messages
Eviction:

1. Gets all message IDs from HashMap
2. Selects random index using 'Math.random()'
3. Removes selected message from both list and HashMap

Message Size Enforcement

Messages have a fixed logical size to simulate real memory management:
Each message occupies exactly 'message.size' bytes (default: 512)
Total cache size = 'cache.capacity × message.size' (e.g., 16 × 512 = 8KB)
Field limits enforced in Message constructor:
Content exceeding 'max.content.length' is truncated
Sender/receiver exceeding their limits are truncated
Ensures predictable memory usage

CacheDisk Integration

The system integrates cache and disk storage for transparent access:

1. Store Operation ('MessageManager.storeMessage()'):
   Writes message to disk
   Adds message to cache

2. Retrieve Operation ('MessageManager.retrieveMessage()'):
   First checks cache (cache hit = fast access)
   If not in cache (cache miss):
   Loads message from disk
   Adds to cache for future access
   Returns message

CACHE PERFORMANCE EVALUATION

Testing Strategy: LRU

RESULTS:

Cache Hits: 175 / 1000 accesses
Cache Misses: 825 / 1000 accesses
Hit Ratio: 17.50%
Miss Ratio: 82.50%

Testing Strategy: LIFO

RESULTS:

Cache Hits: 169 / 1000 accesses
Cache Misses: 831 / 1000 accesses
Hit Ratio: 16.90%
Miss Ratio: 83.10%

Testing Strategy: RANDOM

RESULTS:

Cache Hits: 160 / 1000 accesses
Cache Misses: 840 / 1000 accesses
Hit Ratio: 16.00%
Miss Ratio: 84.00%
